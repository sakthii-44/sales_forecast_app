# -*- coding: utf-8 -*-
"""sales model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x5-4D4XxiiCtEk_To-lgpf8f_rafqzUc
"""

pip install pandas matplotlib seaborn prophet streamlit



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from prophet import Prophet
from scipy import stats
import numpy as np
from itertools import combinations



# Load data
df = pd.read_csv("/content/stores_sales_forecasting.csv", encoding='windows-1252')

print(df)

df.head()

df.describe()

df.shape

# Drop unnecessary columns
columns_to_drop = [
    'Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode', 'Customer ID',
    'Segment', 'Postal Code', 'Region',
    'Product ID', 'Category', 'Sub-Category', 'Quantity'
]

# Make sure the column names actually exist in your DataFrame
df_reduced = df.drop(columns=columns_to_drop, errors='ignore')

# Check the remaining columns
print(df_reduced.columns)

print(df_reduced)

print(df)

df['Order Date'] = pd.to_datetime(df['Order Date'])

# Group sales by date
daily_sales = df.groupby('Order Date')['Sales'].sum().reset_index()

# Sort by date
daily_sales = daily_sales.sort_values('Order Date')
print(daily_sales)

daily_sales['Rolling Avg'] = daily_sales['Sales'].rolling(window=7).mean()

plt.figure(figsize=(14,7))
sns.lineplot(data=daily_sales, x='Order Date', y='Sales', label='Daily Sales')
sns.lineplot(data=daily_sales, x='Order Date', y='Rolling Avg', label='7-Day Avg', color='orange')
plt.title('Daily Sales with 7-Day Rolling Average')
plt.xlabel('Order Date')
plt.ylabel('Sales')
plt.xticks(rotation=45)
plt.tight_layout()
plt.legend()
plt.show()

plt.figure(figsize=(14, 6))
plt.plot(daily_sales['Order Date'], daily_sales['Sales'], label='Daily Sales')
plt.title('Daily Sales Over Time')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.show()

daily_sales.set_index('Order Date', inplace=True)

# Resample to monthly data
monthly_sales = daily_sales['Sales'].resample('M').sum()
monthly_sales.plot(figsize=(14, 6), title='Monthly Sales')
plt.show()



df['Order Date'] = pd.to_datetime(df['Order Date'])

# Plot Sales Over Time
plt.figure(figsize=(15, 5))
sns.lineplot(data=df, x="Order Date", y="Sales")
plt.title("Sales Over Time")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import pandas as pd
from scipy import stats
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import combinations

num_features = ['Sales', 'Quantity', 'Discount','Profit']

# Set up the plotting area
plt.figure(figsize=(12, 8))

# Plot histograms for each numerical feature
for i, feature in enumerate(num_features):
    plt.subplot(2, 2, i + 1)
    sns.histplot(df[feature], kde=True, bins=30, color='skyblue')
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='RdBu', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

numerical_features = ['Sales', 'Quantity', 'Discount', 'Profit']

# Detect outliers using IQR for each numerical feature
for feature in numerical_features:
    Q1 = df[feature].quantile(0.25)
    Q3 = df[feature].quantile(0.75)
    IQR = Q3 - Q1

    # Define lower and upper bounds
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Filter outliers
    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]

    print(f'Feature: {feature}')
    print(f'Number of Outliers: {outliers.shape[0]}')
    print(outliers[[feature]])

num_features = ['Sales', 'Quantity', 'Discount', 'Profit']

# Set up the plotting area
plt.figure(figsize=(12, 8))

# Plot simple box plots for each numerical feature
for i, feature in enumerate(num_features):
    plt.subplot(2, 2, i + 1)
    sns.boxplot(y=df[feature], color='lightblue')
    plt.title(f'Box Plot of {feature}')

plt.tight_layout()
plt.show()

from scipy.stats.mstats import winsorize

for feature in num_features:
    df[feature] = winsorize(df[feature], limits=[0.05, 0.05])  # Cap 5% on both sides
    print(f"Outliers capped for {feature}")

num_features = ['Sales', 'Quantity', 'Discount', 'Profit']

df_cleaned = df.copy()


for feature in num_features:
    Q1 = df_cleaned[feature].quantile(0.25)
    Q3 = df_cleaned[feature].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df_cleaned = df_cleaned[(df_cleaned[feature] >= lower_bound) & (df_cleaned[feature] <= upper_bound)]

print(f"Data shape before outlier removal: {df.shape}")
print(f"Data shape after outlier removal: {df_cleaned.shape}")

num_features = ['Sales', 'Quantity', 'Discount', 'Profit']

# Set up the plotting area
plt.figure(figsize=(12, 8))

# Plot simple box plots for each numerical feature
for i, feature in enumerate(num_features):
    plt.subplot(2, 2, i + 1)
    sns.boxplot(y=df[feature], color='lightblue')
    plt.title(f'Box Plot of {feature}')

plt.tight_layout()
plt.show()

colors = sns.color_palette('pastel')

# Plot the bar chart with custom colors
df.Region.value_counts().plot(kind="bar", color=colors)

# Add titles and labels for clarity (optional)
plt.title("Region Count")
plt.xlabel("Region")
plt.ylabel("Count")

# Display the plot
plt.show()

categorical_features = ['Ship Mode', 'Segment', 'Region', 'Sub-Category']

for feature in categorical_features:
    print(df[feature].value_counts())
    sns.countplot(x=feature, data=df, palette='deep')  # Corrected 'palette'
    plt.title(f'{feature} Count')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.show()

categorical_features = ['Ship Mode', 'Segment', 'Region', 'Sub-Category']

for feature in categorical_features:
    # Get value counts
    counts = df[feature].value_counts()

    # Plot pie chart
    plt.figure(figsize=(6, 6))
    plt.pie(counts, labels=counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('pastel'))
    plt.title(f'{feature} Distribution')

    plt.show()

plt.figure(figsize=(8, 5))
sns.histplot(df['Sales'], bins=15, kde=True, color='teal')
plt.title('Distribution of Sales')
plt.xlabel('Sales')
plt.ylabel('Count')
plt.grid(True)
plt.show()

sns.violinplot(x='Segment', y='Profit', data=df, palette='dark')
plt.title("Profit Distribution Across Segments")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Sort products by total sales
top_products = df.groupby('Product Name')['Sales'].sum().sort_values(ascending=False).head(10)

plt.figure(figsize=(12, 6))
sns.barplot(x=top_products.index, y=top_products.values, palette='coolwarm')
plt.title('Top 10 Products by Total Sales')
plt.xlabel('Product Name')
plt.ylabel('Total Sales')
plt.xticks(rotation=45, ha='right')
plt.show()

plt.figure(figsize=(12, 6))
sns.barplot(x='Sub-Category', y='Sales', data=df, palette='coolwarm', estimator=sum)
plt.title('Total Sales by Sub-Category')
plt.xlabel('Sub-Category')
plt.ylabel('Total Sales')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(12, 6))
sns.scatterplot(data=df, x='Sales', y='Profit', hue='Sub-Category', palette='tab10')
plt.title('Sales vs Profit by Sub-Category')
plt.xlabel('Sales')
plt.ylabel('Profit')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

df.columns

from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error

# --- Sample input ---
# df = pd.read_csv('your_data.csv')
# Assume df has columns: 'date', 'y' (target), and some categorical & numerical columns

# --- Prepare data ---
df = df.copy()

# Convert date column to datetime if needed (replace 'date' with your date column name)
df['date'] = pd.to_datetime(df['Order Date'])

# Sort by date to maintain time order
df = df.sort_values('date').reset_index(drop=True)

# Fill missing target values (if any) by forward fill, then drop remaining NA rows in target
df['y'] = df['Sales'].fillna(method='ffill')
df = df.dropna(subset=['Sales']).reset_index(drop=True)

# --- Feature engineering ---

# Create lag features
lags = [1, 2, 7]
for lag in lags:
    df[f'lag_{lag}'] = df['Sales'].shift(lag)

# Rolling statistics
df['roll_mean_3'] = df['Sales'].shift(1).rolling(window=3).mean()
df['roll_std_3'] = df['Sales'].shift(1).rolling(window=3).std()
df['roll_mean_7'] = df['Sales'].shift(1).rolling(window=7).mean()
df['roll_std_7'] = df['Sales'].shift(1).rolling(window=7).std()

# Date-based features
df['month'] = df['date'].dt.month
df['year'] = df['date'].dt.year
df['day_of_week'] = df['date'].dt.dayofweek
df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)

# Fill missing lag and rolling feature values with mean or zero
df.fillna(df.mean(numeric_only=True), inplace=True)

# --- Encoding categorical columns (example) ---
# Replace ['cat_col1', 'cat_col2'] with your categorical columns
categorical_cols = ['cat_col1', 'cat_col2']  # Example, replace with your actual categorical column names

for col in categorical_cols:
    if col in df.columns:
        df = pd.get_dummies(df, columns=[col], drop_first=True)

# --- Define features and target ---

exclude_cols = ['date', 'Sales']  # exclude date and target from features
feature_cols = [col for col in df.columns if col not in exclude_cols]

X = df[feature_cols]
y = df['y']

# --- Train-test split ---

test_period = 6  # number of periods for testing
train_X, test_X = X[:-test_period], X[-test_period:]
train_y, test_y = y[:-test_period], y[-test_period:]

print(f"Train size: {train_X.shape[0]}, Test size: {test_X.shape[0]}")
print(f"Features used: {len(feature_cols)}")

# --- Model training ---

model = XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=6,
    random_state=42
)

# Convert to numpy arrays to avoid dtype errors
# --- Define features and target ---

exclude_cols = ['date', 'Sales', 'Order ID']  # Add any other string/ID columns here
feature_cols = [col for col in df.columns if col not in exclude_cols and pd.api.types.is_numeric_dtype(df[col])]

X = df[feature_cols]
y = df['Sales']
# --- Train-test split ---
test_period = 6  # or whatever your test size is
train_X, test_X = X[:-test_period], X[-test_period:]
train_y, test_y = y[:-test_period], y[-test_period:]

# Convert to numpy arrays
train_X_np = train_X.values.astype(np.float32)
train_y_np = train_y.values.astype(np.float32)
test_X_np = test_X.values.astype(np.float32)

# Fit model
model.fit(train_X_np, train_y_np)

# Predict and evaluate
preds = model.predict(test_X_np)
mae = mean_absolute_error(test_y, preds)

print(f"Test MAE: {mae:.4f}")

# Show results
results = pd.DataFrame({
    'Actual': test_y.values,
    'Predicted': preds
})
print(results)

import matplotlib.pyplot as plt

# Create DataFrame for visualization
plot_df = df[['date', 'Sales']].copy()
plot_df['type'] = 'Train'
plot_df.loc[plot_df.index >= len(df) - test_period, 'type'] = 'Actual'

# Add forecast
forecast_df = pd.DataFrame({
    'date': df['date'].iloc[-test_period:].values,
    'Sales': preds,
    'type': 'Forecast'
})

# Combine
plot_df = pd.concat([plot_df, forecast_df], ignore_index=True)

# ✅ Zoom in: show only recent N days (e.g. last 90 days of actual + forecast)
days_to_show = 90
latest_date = plot_df['date'].max()
start_date = latest_date - pd.Timedelta(days=days_to_show)
plot_df = plot_df[plot_df['date'] >= start_date]

# Plot
plt.figure(figsize=(14, 6))

# Plot Train
train_data = plot_df[plot_df['type'] == 'Train']
plt.plot(train_data['date'], train_data['Sales'], label='Train', color='blue')

# Plot Actual
actual_data = plot_df[plot_df['type'] == 'Actual']
plt.plot(actual_data['date'], actual_data['Sales'], label='Actual', color='green')

# Plot Forecast
forecast_data = plot_df[plot_df['type'] == 'Forecast']
plt.plot(forecast_data['date'], forecast_data['Sales'], label='Forecast', color='orange', linestyle='--')

# Formatting
plt.title('XGBoost Forecast (Zoomed In)')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()

plt.show()

import matplotlib.pyplot as plt

# --- Visualization: Line plot of actual vs predicted ---
plt.figure(figsize=(10, 5))
plt.plot(test_y.values, label='Actual', marker='o', linestyle='-')
plt.plot(preds, label='Predicted', marker='x', linestyle='--')
plt.title('Actual vs Predicted Values')
plt.xlabel('Time Step')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from xgboost import XGBRegressor

# --- Step 1: Prepare data ---
df_fc = df.copy()  # Make sure `df` is already loaded with 'Order Date' and 'Sales'

# Ensure datetime format and sort
df_fc['date'] = pd.to_datetime(df_fc['Order Date'])
df_fc = df_fc.sort_values('date').reset_index(drop=True)
df_fc['Sales'] = df_fc['Sales'].fillna(method='ffill')
df_fc = df_fc.dropna(subset=['Sales']).reset_index(drop=True)

# --- Step 2: Feature engineering function ---
def create_features(data):
    data['lag_1'] = data['Sales'].shift(1)
    data['lag_2'] = data['Sales'].shift(2)
    data['lag_7'] = data['Sales'].shift(7)

    data['roll_mean_3'] = data['Sales'].shift(1).rolling(window=3).mean()
    data['roll_std_3'] = data['Sales'].shift(1).rolling(window=3).std()
    data['roll_mean_7'] = data['Sales'].shift(1).rolling(window=7).mean()
    data['roll_std_7'] = data['Sales'].shift(1).rolling(window=7).std()

    data['month'] = data['date'].dt.month
    data['year'] = data['date'].dt.year
    data['day_of_week'] = data['date'].dt.dayofweek
    data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)

    return data

# Apply feature engineering
df_fc = create_features(df_fc)
df_fc.fillna(df_fc.mean(numeric_only=True), inplace=True)

# --- Step 3: Model training ---
feature_cols = [
    'lag_1', 'lag_2', 'lag_7',
    'roll_mean_3', 'roll_std_3', 'roll_mean_7', 'roll_std_7',
    'month', 'year', 'day_of_week', 'is_weekend'
]

X_train = df_fc[feature_cols].astype(np.float32)
y_train = df_fc['Sales'].astype(np.float32)

model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)
model.fit(X_train, y_train)

# --- Step 4: Forecast next 30 days ---
last_date = df_fc['date'].max()
future_days = 30  # Forecast next 30 days

future_predictions = []

for i in range(future_days):
    next_date = last_date + pd.Timedelta(days=1)

    # Create a new row for the next date
    new_row = {'date': next_date, 'Sales': np.nan}
    df_fc = pd.concat([df_fc, pd.DataFrame([new_row])], ignore_index=True)

    df_fc = create_features(df_fc)
    df_fc.fillna(df_fc.mean(numeric_only=True), inplace=True)

    # Prepare the feature set for prediction
    X_pred = df_fc[feature_cols].iloc[[-1]].astype(np.float32)

    # Predict sales
    next_sales = model.predict(X_pred)[0]

    # Save prediction
    future_predictions.append({'date': next_date, 'Sales': next_sales})

    # Update df_fc with the predicted Sales
    df_fc.at[df_fc.index[-1], 'Sales'] = next_sales

    # Move to next day
    last_date = next_date

# --- Step 5: Output forecast ---
forecast_df = pd.DataFrame(future_predictions)
print(forecast_df)

import matplotlib.pyplot as plt

# Combine actual data and forecast
historical = df_fc[['date', 'Sales']].copy()
historical = historical[historical['date'] <= forecast_df['date'].min() - pd.Timedelta(days=1)]

# Combine historical and forecast for plotting
plot_df = pd.concat([historical, forecast_df], ignore_index=True)

# Plotting
plt.figure(figsize=(14, 6))
plt.plot(historical['date'], historical['Sales'], label='Historical Sales', color='blue')
plt.plot(forecast_df['date'], forecast_df['Sales'], label='Forecast (Next 30 Days)', color='orange', linestyle='--')

# Formatting
plt.title('XGBoost Sales Forecast - Next 30 Days')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- Step 1: Create example historical data (replace with your df_fc) ---
dates_hist = pd.date_range(start='2025-04-01', periods=60, freq='D')
sales_hist = 100 + np.random.normal(0, 10, size=60)  # example sales with noise
df_fc = pd.DataFrame({'date': dates_hist, 'Sales': sales_hist})

# --- Step 2: Create example forecast data (replace with your forecast_df) ---
dates_forecast = pd.date_range(start=dates_hist[-1] + pd.Timedelta(days=1), periods=30)
sales_forecast = 110 + np.random.normal(0, 8, size=30)  # forecasted sales with noise
forecast_df = pd.DataFrame({'date': dates_forecast, 'Sales': sales_forecast})

# --- Step 3: Create example actual sales for forecast period (replace with your actual_df) ---
sales_actual = 108 + np.random.normal(0, 9, size=30)  # actual sales, similar but different noise
actual_df = pd.DataFrame({'date': dates_forecast, 'Sales': sales_actual})

# --- Step 4: Prepare historical data up to forecast start date ---
historical = df_fc[df_fc['date'] < forecast_df['date'].min()]

# --- Step 5: Combine for plotting ---
plot_df = pd.concat([historical, forecast_df], ignore_index=True)

# --- Step 6: Plot historical and forecast sales ---
plt.figure(figsize=(14, 6))
plt.plot(historical['date'], historical['Sales'], label='Historical Sales', color='blue')
plt.plot(forecast_df['date'], forecast_df['Sales'], label='Forecast (Next 30 Days)', color='orange', linestyle='--')
plt.title('Sales Forecast - Next 30 Days')
plt.xlabel('Date')
plt.ylabel('Sales')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# --- Step 7: Calculate accuracy metrics between forecast and actual ---
comparison_df = forecast_df.merge(actual_df, on='date', suffixes=('_forecast', '_actual'))
mae = mean_absolute_error(comparison_df['Sales_actual'], comparison_df['Sales_forecast'])
rmse = np.sqrt(mean_squared_error(comparison_df['Sales_actual'], comparison_df['Sales_forecast']))

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")

import matplotlib.pyplot as plt
plt.plot(df_fc['date'][-60:], df_fc['Sales'][-60:])
plt.title("Recent Sales")
plt.xticks(rotation=45)
plt.show()